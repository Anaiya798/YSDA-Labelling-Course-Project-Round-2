# Проектный раунд 2. Распознавание парафраз (NLP)
### 1. Работа с данными  
* Для начала мы провели первичную обработку. Обработаны были только
первые 500 000 данных, т.к. это нам показалось уже достаточно для
дальнейшего дообучения предобученной модели.  
* Все данные из предоставленного json-а мы сгруппировали по
пользовательским сессиям (session_id) и в рамках каждой сессии оставили
только один экземпляр данных (т.к. было замечено, что экземпляры в рамках
одной сессии мало отличаются).  
* После этого из каждого экземпляра данных мы выделили пары (prev_query,
query) и (query, next_query).  
* Все полученные пары были проверены на парафразы с помощью метрики
cosine_similarity (предварительно все запросы были приведены к нормальной
форме с помощью стемминга). Векторы-эмбеддинги были получены с
помощью CountVectorizer. Повторяющиеся пары пропускали.  
* Эмпирическим путем было выяснено, что все пары, имеющие значение
cosine_similarity ≥ 0.15, можно считать парафразами по нашим меркам. Мы
такие пары выкинули из общего датасета пар, посчитав их парафразами
(true_paraphrases).   
* На оставшихся обработанных парах была протестирована предобученная
модель [RuBERT](https://huggingface.co/cointegrated/rubert-base-cased-dpparaphrase-detection).  
* Мы решили использовать подход human-in-the-loop: посмотрели, на каких
парах модель не уверена (уверенность в каждом из 2-ух классов менее 60%).
Таких оказалось чуть более 6 тысяч. Все эти пары было решено отдать на
разметку толокерам.  
* В проекте на Толоке создали пул из 5 бесплатных тренировочных, для
перехода в основной пулл толокерам нужно было допустить не более одной
ошибки. В тренировочных заданиях постарались учесть и весьма
замысловатые случаи.  
* Создали 48 контрольных заданий. В половине были представлены парафразы,
в половине - не парафразы.  
* Ввели дополнительный скилл paraphrases_quality, в который после 3 ответов
исполнителя записывается процент верных. Отсеиваем толокеров с
paraphrases_quality менее 80%.  
* На странице 15 заданий: 14 обычных и 1 контрольное.  
* Цена за страницу - $0.01.  
* Полученные результаты агрегировали по модели Dawid-Skene.  
* Было потрачено 17.173$ / 20$.  

### 2. Создание пайплайна и тренировка модели  
* В качестве трейна модели мы использовали объединение трёх множеств:
  - true paraphrases, которым была назначена метка 1;  
  - пары запросов, где RuBERT из-под коробки (ещё необученный) выдал 0 с большей вероятностью (≥ 0.8), им была назначена метка 0;  
  - размеченные толокерами данные.  
* Эти данные были разделены на 4 части. Дальше обучалось 4 RuBERT: трейн
каждого состоял из 3 частей, оставшаяся часть была для него валидационной.  
* Затем на скорах этих моделей обучили CatBoost.  

